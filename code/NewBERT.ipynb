{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"T4","provenance":[]},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10258418,"sourceType":"datasetVersion","datasetId":6345928},{"sourceId":10258423,"sourceType":"datasetVersion","datasetId":6345932},{"sourceId":10262339,"sourceType":"datasetVersion","datasetId":6348456},{"sourceId":10264197,"sourceType":"datasetVersion","datasetId":6349883}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importation des biblioth√®ques n√©cessaires pour le traitement du langage naturel et l'apprentissage automatique\nimport nltk\nimport os\nimport csv\nimport math\nimport random\nimport logging\nimport itertools\nimport time\nimport re\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom tqdm import tqdm\nfrom dataclasses import dataclass\nfrom typing import Optional, Tuple\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    confusion_matrix,\n    roc_auc_score,\n    balanced_accuracy_score,\n    matthews_corrcoef\n)\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import (\n    BertModel, BertConfig, BertPreTrainedModel,\n    BertTokenizer, AdamW, get_linear_schedule_with_warmup\n)\nfrom nltk.corpus import wordnet as wn\nfrom torch.nn.functional import softmax\nfrom tabulate import tabulate\n\n# Configuration de la journalisation pour un suivi d√©taill√© des op√©rations\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n#T√©l√©chargement des ressources WordNet n√©cessaires\nnltk.download('wordnet', download_dir='/kaggle/working/nltk_data')\nnltk.data.path.append('/kaggle/working/nltk_data')","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:25:35.082140Z","iopub.execute_input":"2024-12-21T16:25:35.082437Z","iopub.status.idle":"2024-12-21T16:25:40.819073Z","shell.execute_reply.started":"2024-12-21T16:25:35.082409Z","shell.execute_reply":"2024-12-21T16:25:40.818339Z"},"id":"etBj-YbIm87k","outputId":"be9c35d1-bce0-411c-fab6-a1a3a2b9127e","trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to\n[nltk_data]     /kaggle/working/nltk_data...\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#Google Colab Unzipping Methods\n#Kaggle Notebook Unzipping Methods\n#Python's zipfile module\n\nimport zipfile\n\nwith zipfile.ZipFile('/kaggle/working/nltk_data/corpora/wordnet.zip', 'r') as zip_ref:\n    zip_ref.extractall('//kaggle/working/nltk_data/corpora/')","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:25:46.705973Z","iopub.execute_input":"2024-12-21T16:25:46.706401Z","iopub.status.idle":"2024-12-21T16:25:46.932587Z","shell.execute_reply.started":"2024-12-21T16:25:46.706376Z","shell.execute_reply":"2024-12-21T16:25:46.931698Z"},"id":"qXCtVC6A8OOx","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Structure repr√©sentant un enregistrement pour la s√©lection de gloses\nfrom collections import namedtuple\nGlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"identifiant\", \"phrase\", \"cles_sens\", \"glosses\", \"cibles\"])\nEntreesBert = namedtuple(\"EntreesBert\", [\"ids_entree\", \"masque_entree\", \"ids_segment\", \"id_etiquette\"])\n\n# D√©finition des parties du discours pour WordNet\nPARTIES_DISCOURS_WORDNET = {'VERBE': wn.VERB, 'NOM': wn.NOUN, 'ADJECTIF': wn.ADJ, 'ADVERBE': wn.ADV}\n\ndef obtenir_glosses(lemme, pos):\n    \"\"\"\n    R√©cup√®re les d√©finitions pour un mot donn√© dans WordNet.\n\n    L'utilisateur fournit un lemme et une partie du discours,\n    la fonction renvoie un dictionnaire de d√©finitions.\n    \"\"\"\n    resultats = dict()\n    pos_wordnet = PARTIES_DISCOURS_WORDNET.get(pos, None) if pos is not None else None\n    morphemes = wn._morphy(lemme, pos=pos_wordnet) if pos is not None else []\n\n    for synset in set(wn.synsets(lemme, pos=pos_wordnet)):\n        cle_sens = None\n        for lemme_synset in synset.lemmas():\n            if lemme_synset.name().lower() == lemme.lower():\n                cle_sens = lemme_synset.key()\n                break\n            elif lemme_synset.name().lower() in morphemes:\n                cle_sens = lemme_synset.key()\n\n        if cle_sens is not None:\n            resultats[cle_sens] = synset.definition()\n\n    return resultats\n\nclass JeuDonneesWSD(Dataset):\n    \"\"\"Jeu de donn√©es personnalis√© pour la d√©sambigu√Øsation lexicale\"\"\"\n    def __init__(self, caracteristiques):\n        self.caracteristiques = caracteristiques\n\n    def __getitem__(self, index):\n        return self.caracteristiques[index]\n\n    def __len__(self):\n        return len(self.caracteristiques)","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:25:53.169183Z","iopub.execute_input":"2024-12-21T16:25:53.169458Z","iopub.status.idle":"2024-12-21T16:25:54.556187Z","shell.execute_reply.started":"2024-12-21T16:25:53.169437Z","shell.execute_reply":"2024-12-21T16:25:54.555456Z"},"id":"bObSAtLatKoc","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class BertWSD(BertPreTrainedModel):\n    \"\"\"\n    Mod√®le BERT sp√©cialis√© pour la d√©sambigu√Øsation lexicale.\n\n    Le mod√®le √©tend BertPreTrainedModel avec une couche de classification lin√©aire.\n    \"\"\"\n    def __init__(self, config):\n        super().__init__(config)\n        self.bert = BertModel(config)\n        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n        self.couche_classement = torch.nn.Linear(config.hidden_size, 1)\n        self.init_weights()\n\ndef calculer_perte_ponderee(perte, facteur_ponderation):\n    \"\"\"\n    Calcule une perte pond√©r√©e avec un facteur de correction.\n\n    Permet d'ajuster la contribution de la perte lors de l'entra√Ænement.\n    \"\"\"\n    carre_facteur = facteur_ponderation ** 2\n    return 1 / (2 * carre_facteur) * perte + math.log(1 + carre_facteur)\n\ndef tronquer_sequence_paire(jetons_a, jetons_b, longueur_max):\n    \"\"\"\n    Tronque une paire de s√©quences √† une longueur maximale.\n\n    Assure que la longueur totale des s√©quences ne d√©passe pas la limite.\n    \"\"\"\n    while True:\n        longueur_totale = len(jetons_a) + len(jetons_b)\n        if longueur_totale <= longueur_max:\n            break\n        if len(jetons_a) > len(jetons_b):\n            jetons_a.pop()\n        else:\n            jetons_b.pop()","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:26:02.569264Z","iopub.execute_input":"2024-12-21T16:26:02.569548Z","iopub.status.idle":"2024-12-21T16:26:02.575353Z","shell.execute_reply.started":"2024-12-21T16:26:02.569527Z","shell.execute_reply":"2024-12-21T16:26:02.574678Z"},"id":"vwblPaVRm87m","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom typing import Optional, Tuple\n\n@dataclass\nclass ConfigurationEchantillonnage:\n    \"\"\"Configuration pour l'√©chantillonnage des donn√©es.\n    \n    Attributes:\n        taille_max: Nombre maximum d'√©chantillons √† prendre\n        plage: Tuple optionnel (debut, fin) pour sp√©cifier une plage de lignes\n    \"\"\"\n    taille_max: Optional[int] = None\n    plage: Optional[Tuple[int, int]] = None\n\ndef creer_enregistrements_depuis_csv(chemin_csv, fonction_deserialisation, config_echantillonnage=None):\n    \"\"\"\n    Cr√©e des enregistrements √† partir d'un fichier CSV avec options d'√©chantillonnage avanc√©es.\n    \n    Args:\n        chemin_csv: Chemin vers le fichier CSV\n        fonction_deserialisation: Fonction pour convertir les lignes CSV\n        config_echantillonnage: Configuration d'√©chantillonnage (taille_max et plage)\n        \n    Returns:\n        Liste des enregistrements √©chantillonn√©s\n    \"\"\"\n    enregistrements = []\n    \n    with open(chemin_csv, 'r', encoding='utf-8', newline='') as fichier:\n        lecteur = csv.reader(fichier)\n        next(lecteur)  # Ignorer l'en-t√™te\n        \n        # Convertir l'it√©rateur en liste pour permettre l'indexation\n        toutes_lignes = list(lecteur)\n        \n        # D√©terminer les indices de d√©but et fin\n        debut = 0\n        fin = len(toutes_lignes)\n        \n        if config_echantillonnage and config_echantillonnage.plage:\n            debut = max(0, config_echantillonnage.plage[0] - 1)  # -1 car les utilisateurs comptent √† partir de 1\n            fin = min(len(toutes_lignes), config_echantillonnage.plage[1])\n        \n        # Appliquer la limitation de taille si sp√©cifi√©e\n        if config_echantillonnage and config_echantillonnage.taille_max:\n            fin = min(fin, debut + config_echantillonnage.taille_max)\n        \n        # Cr√©er les enregistrements pour la plage s√©lectionn√©e\n        for ligne in toutes_lignes[debut:fin]:\n            enregistrements.append(fonction_deserialisation(ligne))\n            \n        logger.info(f\"√âchantillonnage effectu√© - Plage : {debut+1} √† {fin} - \"\n                   f\"Nombre d'enregistrements : {len(enregistrements)}\")\n    \n    return enregistrements\n\ndef deserialiser_enregistrement_csv(ligne):\n    \"\"\"\n    Convertit une ligne CSV en enregistrement de s√©lection de gloses.\n    \"\"\"\n    return GlossSelectionRecord(\n        ligne[0],  # identifiant\n        ligne[1],  # phrase\n        eval(ligne[2]),  # cles_sens\n        eval(ligne[3]),  # glosses\n        [int(t) for t in eval(ligne[4])]  # cibles\n    )\n\ndef charger_jeu_donnees(\n    chemin_csv,\n    tokeniseur,\n    longueur_sequence_max,\n    debut_plage=None,\n    fin_plage=None,\n    taille_max=None\n):\n    \"\"\"\n    Charge un jeu de donn√©es avec options d'√©chantillonnage avanc√©es.\n    \n    Args:\n        chemin_csv: Chemin vers le fichier CSV\n        tokeniseur: Tokeniseur BERT\n        longueur_sequence_max: Longueur maximale des s√©quences\n        debut_plage: Indice de d√©but pour l'√©chantillonnage (commen√ßant √† 1)\n        fin_plage: Indice de fin pour l'√©chantillonnage\n        taille_max: Nombre maximum d'√©chantillons √† prendre\n    \"\"\"\n    config = ConfigurationEchantillonnage(\n        taille_max=taille_max,\n        plage=(debut_plage, fin_plage) if debut_plage and fin_plage else None\n    )\n    \n    enregistrements = creer_enregistrements_depuis_csv(\n        chemin_csv,\n        deserialiser_enregistrement_csv,\n        config\n    )\n    \n    caracteristiques = creer_caracteristiques_depuis_enregistrements(\n        enregistrements,\n        longueur_sequence_max,\n        tokeniseur\n    )\n    \n    logger.info(f\"Charg√© {len(caracteristiques)} √©chantillons depuis {chemin_csv}\")\n    \n    return JeuDonneesWSD(caracteristiques)\n\ndef creer_caracteristiques_depuis_enregistrements(enregistrements, longueur_seq_max, tokeniseur):\n    \"\"\"\n    Convertit les enregistrements en caract√©ristiques pour BERT.\n\n    Pr√©pare les donn√©es d'entr√©e pour le mod√®le en tokenisant et formatant.\n    \"\"\"\n    caracteristiques = []\n    for enregistrement in tqdm(enregistrements, desc=\"Conversion des donn√©es\"):\n        jetons_a = tokeniseur.tokenize(enregistrement.phrase)\n        sequences = [(gloss, 1 if i in enregistrement.cibles else 0) for i, gloss in enumerate(enregistrement.glosses)]\n\n        paires = []\n        for seq, etiquette in sequences:\n            jetons_b = tokeniseur.tokenize(seq)\n            tronquer_sequence_paire(jetons_a, jetons_b, longueur_seq_max - 3)\n\n            jetons = jetons_a + ['[SEP]']\n            ids_segment = [0] * len(jetons)\n\n            jetons += jetons_b + ['[SEP]']\n            ids_segment += [1] * (len(jetons_b) + 1)\n\n            jetons = ['[CLS]'] + jetons\n            ids_segment = [0] + ids_segment\n\n            ids_entree = tokeniseur.convert_tokens_to_ids(jetons)\n            masque_entree = [1] * len(ids_entree)\n\n            longueur_padding = longueur_seq_max - len(ids_entree)\n            ids_entree += [0] * longueur_padding\n            masque_entree += [0] * longueur_padding\n            ids_segment += [0] * longueur_padding\n\n            assert len(ids_entree) == longueur_seq_max\n            assert len(masque_entree) == longueur_seq_max\n            assert len(ids_segment) == longueur_seq_max\n\n            paires.append(\n                EntreesBert(ids_entree=ids_entree, masque_entree=masque_entree,\n                            ids_segment=ids_segment, id_etiquette=etiquette)\n            )\n\n        caracteristiques.append(paires)\n\n    return caracteristiques\n\ndef regrouper_lots(lot):\n    \"\"\"\n    Regroupe les lots de donn√©es pour l'entra√Ænement et l'√©valuation.\n\n    Pr√©pare les tenseurs pour l'entr√©e du mod√®le BERT.\n    \"\"\"\n    longueur_seq_max = len(lot[0][0].ids_entree)\n\n    lots_regroupes = []\n    for sous_lot in lot:\n        taille_lot = len(sous_lot)\n        sous_lots_regroupes = [torch.zeros([taille_lot, longueur_seq_max], dtype=torch.long) for _ in range(3)] + \\\n                               [torch.zeros([taille_lot], dtype=torch.long)]\n\n        for i, entree_bert in enumerate(sous_lot):\n            sous_lots_regroupes[0][i] = torch.tensor(entree_bert.ids_entree, dtype=torch.long)\n            sous_lots_regroupes[1][i] = torch.tensor(entree_bert.masque_entree, dtype=torch.long)\n            sous_lots_regroupes[2][i] = torch.tensor(entree_bert.ids_segment, dtype=torch.long)\n            sous_lots_regroupes[3][i] = torch.tensor(entree_bert.id_etiquette, dtype=torch.long)\n\n        lots_regroupes.append(sous_lots_regroupes)\n\n    return lots_regroupes","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:26:17.599403Z","iopub.execute_input":"2024-12-21T16:26:17.599698Z","iopub.status.idle":"2024-12-21T16:26:17.614967Z","shell.execute_reply.started":"2024-12-21T16:26:17.599674Z","shell.execute_reply":"2024-12-21T16:26:17.614099Z"},"id":"iKSduMGFm87n","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def passe_avant_selection_gloses(modele, lots, appareil):\n    \"\"\"\n    R√©alise une passe avant pour la s√©lection de gloses.\n\n    Le syst√®me calcule la perte et les logits pour chaque lot de donn√©es\n    en utilisant le mod√®le BERT sp√©cialis√©.\n    \"\"\"\n    perte_lot = 0\n    liste_logits = []\n    fonction_perte = torch.nn.CrossEntropyLoss()\n\n    for lot in lots:\n        lot = tuple(t.to(appareil) for t in lot)\n        sorties = modele.bert(input_ids=lot[0], attention_mask=lot[1], token_type_ids=lot[2])\n        etat_cache = modele.dropout(sorties[1])\n\n        logits = modele.couche_classement(etat_cache).squeeze(-1)\n        etiquettes = torch.max(lot[3], -1).indices.detach()\n        perte_lot += fonction_perte(logits.unsqueeze(dim=0), etiquettes.unsqueeze(dim=-1))\n        liste_logits.append(logits)\n\n    perte = perte_lot / len(lots)\n    return perte, liste_logits\n\ndef entrainer_wsd(\n    chemin_entrainement,\n    chemin_evaluation,\n    repertoire_sortie= '/kaggle/working/resultats',\n    debut_plage_entrainement=None,\n    fin_plage_entrainement=None,\n    taille_max_entrainement=None,\n    debut_plage_evaluation=None,\n    fin_plage_evaluation=None,\n    taille_max_evaluation=None\n):\n    \"\"\"\n    Entra√Æne un mod√®le de d√©sambigu√Øsation lexicale avec options d'√©chantillonnage avanc√©es.\n    \n    Args:\n        chemin_entrainement: Chemin vers les donn√©es d'entra√Ænement\n        chemin_evaluation: Chemin vers les donn√©es d'√©valuation\n        repertoire_sortie: R√©pertoire pour sauvegarder le mod√®le\n        debut_plage_entrainement: Premi√®re ligne √† inclure pour l'entra√Ænement\n        fin_plage_entrainement: Derni√®re ligne √† inclure pour l'entra√Ænement\n        taille_max_entrainement: Nombre maximum d'√©chantillons d'entra√Ænement\n        debut_plage_evaluation: Premi√®re ligne √† inclure pour l'√©valuation\n        fin_plage_evaluation: Derni√®re ligne √† inclure pour l'√©valuation\n        taille_max_evaluation: Nombre maximum d'√©chantillons d'√©valuation\n    \"\"\"\n    # Configuration des hyperparam√®tres\n    longueur_sequence_max = 128\n    taille_lot = 8\n    nombre_epoques = 1\n    taux_apprentissage = 1e-5\n    graine = 42\n\n    # Configuration de la reproductibilit√©\n    random.seed(graine)\n    np.random.seed(graine)\n    torch.manual_seed(graine)\n    torch.cuda.manual_seed_all(graine)\n\n    # S√©lection et configuration du p√©riph√©rique\n    appareil = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    logger.info(f\"Utilisation du p√©riph√©rique : {appareil}\")\n\n    # Chargement du mod√®le et du tokeniseur\n    nom_modele = '/kaggle/input/model-last'\n    configuration = BertConfig.from_pretrained(nom_modele, num_labels=2)\n    tokeniseur = BertTokenizer.from_pretrained(nom_modele)\n    modele = BertWSD.from_pretrained(nom_modele, config=configuration)\n\n    # Gestion des tokens sp√©ciaux\n    if '[TGT]' not in tokeniseur.additional_special_tokens:\n        tokeniseur.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n        modele.resize_token_embeddings(len(tokeniseur))\n\n    modele.to(appareil)\n\n    # Chargement des donn√©es d'entra√Ænement avec les nouvelles options d'√©chantillonnage\n    logger.info(\"Chargement des donn√©es d'entra√Ænement...\")\n    jeu_donnees_entrainement = charger_jeu_donnees(\n        chemin_entrainement,\n        tokeniseur,\n        longueur_sequence_max,\n        debut_plage=debut_plage_entrainement,\n        fin_plage=fin_plage_entrainement,\n        taille_max=taille_max_entrainement\n    )\n\n    # Cr√©ation du DataLoader pour l'entra√Ænement\n    echantillonneur = RandomSampler(jeu_donnees_entrainement)\n    chargeur_donnees_entrainement = DataLoader(\n        jeu_donnees_entrainement,\n        sampler=echantillonneur,\n        batch_size=taille_lot,\n        collate_fn=regrouper_lots\n    )\n\n    # Configuration de l'optimiseur avec gestion du weight decay\n    no_decay = ['bias', 'LayerNorm.weight']\n    parametres_optimiseur = [\n        {\n            'params': [p for n, p in modele.named_parameters() if not any(nd in n for nd in no_decay)],\n            'weight_decay': 0.01\n        },\n        {\n            'params': [p for n, p in modele.named_parameters() if any(nd in n for nd in no_decay)],\n            'weight_decay': 0.0\n        }\n    ]\n\n    # Initialisation de l'optimiseur et du plannificateur\n    nombre_etapes_totales = len(chargeur_donnees_entrainement) * nombre_epoques\n    optimiseur = AdamW(parametres_optimiseur, lr=taux_apprentissage)\n    plannificateur = get_linear_schedule_with_warmup(\n        optimiseur,\n        num_warmup_steps=0,\n        num_training_steps=nombre_etapes_totales\n    )\n\n    # D√©but de l'entra√Ænement\n    logger.info(\"\\n========== D√©but de l'entra√Ænement ==========\")\n    logger.info(f\"Nombre d'√©chantillons d'entra√Ænement : {len(jeu_donnees_entrainement)}\")\n    logger.info(f\"Nombre d'√©poques : {nombre_epoques}\")\n    logger.info(f\"Taille des lots : {taille_lot}\")\n    \n    meilleures_metriques = {\n        'precision': 0,\n        'rappel': 0,\n        'f1': 0,\n        'epoque': 0\n    }\n\n    for epoque in range(nombre_epoques):\n        modele.train()\n        perte_totale = 0\n        predictions_totales = []\n        etiquettes_totales = []\n\n        with tqdm(chargeur_donnees_entrainement, \n                 desc=f\"√âpoque {epoque+1}/{nombre_epoques}\",\n                 unit=\"lot\") as iterateur_epoque:\n            \n            for etape, lots in enumerate(iterateur_epoque):\n                # Passe avant et calcul de la perte\n                perte, liste_logits = passe_avant_selection_gloses(modele, lots, appareil)\n                \n                # Collecte des pr√©dictions\n                for logits_lot, lot in zip(liste_logits, lots):\n                    predictions = (logits_lot > 0.5).cpu().numpy().astype(int)\n                    etiquettes = lot[3].cpu().numpy()\n                    predictions_totales.extend(predictions)\n                    etiquettes_totales.extend(etiquettes)\n\n                # R√©tropropagation et optimisation\n                optimiseur.zero_grad()\n                perte.backward()\n                torch.nn.utils.clip_grad_norm_(modele.parameters(), 1.0)\n                optimiseur.step()\n                plannificateur.step()\n\n                perte_totale += perte.item()\n                \n                # Calcul des m√©triques interm√©diaires\n                precision_courante = precision_score(\n                    etiquettes_totales, \n                    predictions_totales, \n                    zero_division=0\n                )\n                \n                # Mise √† jour de la barre de progression\n                iterateur_epoque.set_postfix({\n                    'Perte': f'{perte.item():.4f}',\n                    'Pr√©cision': f'{precision_courante:.4f}',\n                    'Taux Apprentissage': f'{plannificateur.get_last_lr()[0]:.6f}'\n                })\n\n        # √âvaluation de fin d'√©poque\n        precision = precision_score(etiquettes_totales, predictions_totales, zero_division=0)\n        rappel = recall_score(etiquettes_totales, predictions_totales, zero_division=0)\n        f1 = f1_score(etiquettes_totales, predictions_totales, zero_division=0)\n\n        # Mise √† jour des meilleures m√©triques\n        if f1 > meilleures_metriques['f1']:\n            meilleures_metriques.update({\n                'precision': precision,\n                'rappel': rappel,\n                'f1': f1,\n                'epoque': epoque + 1\n            })\n            \n            # Sauvegarde du meilleur mod√®le\n            os.makedirs(repertoire_sortie, exist_ok=True)\n            modele.save_pretrained(repertoire_sortie)\n            tokeniseur.save_pretrained(repertoire_sortie)\n\n        # Affichage des r√©sultats de l'√©poque\n        logger.info(f\"\\nR√©sultats de l'√©poque {epoque+1}:\")\n        logger.info(f\"Pr√©cision: {precision:.4f}\")\n        logger.info(f\"Rappel: {rappel:.4f}\")\n        logger.info(f\"Score F1: {f1:.4f}\")\n\n    # R√©sum√© final de l'entra√Ænement\n    logger.info(\"\\n========== Entra√Ænement termin√© ==========\")\n    logger.info(f\"Meilleures m√©triques (√©poque {meilleures_metriques['epoque']}):\")\n    logger.info(f\"Pr√©cision: {meilleures_metriques['precision']:.4f}\")\n    logger.info(f\"Rappel: {meilleures_metriques['rappel']:.4f}\")\n    logger.info(f\"Score F1: {meilleures_metriques['f1']:.4f}\")\n    logger.info(f\"Mod√®le sauvegard√© dans : {repertoire_sortie}\")\n\n    return meilleures_metriques","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:26:52.664613Z","iopub.execute_input":"2024-12-21T16:26:52.664937Z","iopub.status.idle":"2024-12-21T16:26:52.680921Z","shell.execute_reply.started":"2024-12-21T16:26:52.664909Z","shell.execute_reply":"2024-12-21T16:26:52.680056Z"},"id":"TyLGcxD3m87n","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def ecrire_predictions(repertoire_sortie, chemin_evaluation, predictions, suffixe=None):\n    \"\"\"\n    √âcrit les pr√©dictions dans un fichier de sortie CSV.\n\n    Le syst√®me sauvegarde les r√©sultats du mod√®le avec un nommage flexible.\n    \"\"\"\n    os.makedirs(repertoire_sortie, exist_ok=True)\n\n    nom_base = os.path.splitext(os.path.basename(chemin_evaluation))[0]\n    nom_fichier_sortie = f\"{nom_base}_predictions\"\n    if suffixe:\n        nom_fichier_sortie += f\"_{suffixe}\"\n    nom_fichier_sortie += \".csv\"\n\n    chemin_complet_sortie = os.path.join(repertoire_sortie, nom_fichier_sortie)\n\n    try:\n        with open(chemin_evaluation, 'r', newline='', encoding='utf-8') as fichier_eval:\n            lecteur = csv.reader(fichier_eval)\n            donnees_originales = list(lecteur)\n\n        for i, prediction in enumerate(predictions):\n            if i < len(donnees_originales):\n                donnees_originales[i].append(str(prediction))\n\n        with open(chemin_complet_sortie, 'w', newline='', encoding='utf-8') as fichier_sortie:\n            ecrivain = csv.writer(fichier_sortie)\n            ecrivain.writerows(donnees_originales)\n\n        logger.info(f\"Pr√©dictions √©crites dans {chemin_complet_sortie}\")\n\n    except Exception as e:\n        logger.error(f\"Erreur lors de l'√©criture des pr√©dictions : {e}\")\n\ndef evaluer_wsd(\n    modele,\n    tokeniseur,\n    chemin_evaluation,\n    longueur_sequence_max=128,\n    taille_lot_evaluation=16,\n    repertoire_sortie='/kaggle/working/resultEval',\n    suffixe=None,\n    debut_plage_evaluation=None,\n    fin_plage_evaluation=None,\n    taille_max_evaluation=None\n):\n    \"\"\"\n    √âvalue un mod√®le de d√©sambigu√Øsation lexicale (WSD).\n\n    Le syst√®me calcule les performances d√©taill√©es sur un jeu de donn√©es de test.\n    \"\"\"\n    jeu_donnees_evaluation = charger_jeu_donnees(\n        chemin_evaluation,\n        tokeniseur,\n        longueur_sequence_max,\n        debut_plage_evaluation,\n        fin_plage_evaluation,\n        taille_max_evaluation\n    )\n\n    echantillonneur = SequentialSampler(jeu_donnees_evaluation)\n    chargeur_donnees_evaluation = DataLoader(\n        jeu_donnees_evaluation,\n        sampler=echantillonneur,\n        batch_size=taille_lot_evaluation,\n        collate_fn=regrouper_lots\n    )\n\n    logger.info(\"***** D√©but de l'√©valuation *****\")\n    logger.info(f\"Nombre d'exemples : {len(jeu_donnees_evaluation)}\")\n    logger.info(f\"Taille des lots : {taille_lot_evaluation}\")\n\n    perte_evaluation = 0.0\n    nombre_etapes_evaluation = 0\n    predictions = []\n    verites_terrain = []\n    appareil = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    modele.to(appareil)\n    modele.eval()\n\n    for lots in tqdm(chargeur_donnees_evaluation, desc=\"√âvaluation en cours\"):\n        with torch.no_grad():\n            perte, liste_logits = passe_avant_selection_gloses(modele, lots, appareil)\n\n        perte_evaluation += perte\n\n        # Collecte des pr√©dictions et des v√©rit√©s de terrain\n        for logits_lot, lot in zip(liste_logits, lots):\n            predictions.extend((logits_lot > 0.5).cpu().numpy().astype(int))\n            verites_terrain.extend(lot[3].cpu().numpy())\n\n        nombre_etapes_evaluation += 1\n\n    perte_evaluation = perte_evaluation / nombre_etapes_evaluation\n\n    # Calcul des m√©triques d√©taill√©es\n    accuracy = accuracy_score(verites_terrain, predictions)\n    balanced_accuracy = balanced_accuracy_score(verites_terrain, predictions)\n    precision = precision_score(verites_terrain, predictions, zero_division=0)\n    rappel = recall_score(verites_terrain, predictions, zero_division=0)\n    f1 = f1_score(verites_terrain, predictions, zero_division=0)\n    mcc = matthews_corrcoef(verites_terrain, predictions)\n    specificity = recall_score(verites_terrain, predictions, pos_label=0)\n    matrice_confusion = confusion_matrix(verites_terrain, predictions)\n    roc_auc = roc_auc_score(verites_terrain, predictions)\n\n    metriques = {\n        'perte': perte_evaluation,\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_accuracy,\n        'precision': precision,\n        'rappel': rappel,\n        'f1_score': f1,\n        'mcc': mcc,\n        'specificity': specificity,\n        'roc_auc': roc_auc,\n        'matrice_confusion': matrice_confusion\n    }\n\n    # √âcriture des pr√©dictions\n    ecrire_predictions(repertoire_sortie, chemin_evaluation, predictions, suffixe='prediction_v1')\n\n    # Journalisation des r√©sultats d√©taill√©s\n    logger.info(\"\\nüìä R√©sultats d'√©valuation :\")\n    for metrique, valeur in metriques.items():\n        if metrique != 'matrice_confusion':\n            logger.info(f\"{metrique.capitalize().replace('_', ' ')} : {valeur:.4f}\")\n    logger.info(\"\\nMatrice de confusion :\")\n    logger.info(np.array2string(metriques['matrice_confusion'], separator=', '))\n\n    # Cr√©ation d'un rapport au format CSV\n    chemin_rapport = os.path.join(repertoire_sortie, f\"rapport_evaluation_{suffixe or 'defaut'}.csv\")\n    with open(chemin_rapport, 'w', newline='', encoding='utf-8') as fichier:\n        ecrivain = csv.writer(fichier)\n        ecrivain.writerow(['M√©trique', 'Valeur'])\n        for metrique, valeur in metriques.items():\n            if metrique == 'matrice_confusion':\n                continue  # La matrice de confusion n'est pas incluse dans le CSV\n            ecrivain.writerow([metrique.capitalize().replace('_', ' '), f\"{valeur:.4f}\"])\n\n    logger.info(f\"Rapport d'√©valuation sauvegard√© dans {chemin_rapport}\")\n\n    return metriques\n\ndef creer_visualisations(metriques, repertoire_sortie, suffixe, verites_terrain):\n    \"\"\"Cr√©e les visualisations des r√©sultats.\"\"\"\n    try:\n        import seaborn as sns\n        import matplotlib.pyplot as plt\n\n        # Matrice de confusion\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            metriques['matrice_confusion'],\n            annot=True,\n            fmt='d',\n            cmap='Blues',\n            xticklabels=['Classe 0', 'Classe 1'],\n            yticklabels=['Classe 0', 'Classe 1']\n        )\n        plt.xlabel(\"Pr√©dictions\")\n        plt.ylabel(\"V√©rit√© terrain\")\n        plt.title(\"Matrice de confusion\")\n        \n        chemin_matrice = os.path.join(repertoire_sortie, \n                                     f\"matrice_confusion_{suffixe or 'defaut'}.png\")\n        plt.savefig(chemin_matrice, bbox_inches='tight', dpi=300)\n        plt.close()\n\n        # Distribution des classes\n        plt.figure(figsize=(8, 6))\n        sns.countplot(x=verites_terrain)\n        plt.title(\"Distribution des classes\")\n        plt.xlabel(\"Classe\")\n        plt.ylabel(\"Nombre d'exemples\")\n        \n        chemin_distribution = os.path.join(repertoire_sortie,\n                                         f\"distribution_classes_{suffixe or 'defaut'}.png\")\n        plt.savefig(chemin_distribution, bbox_inches='tight', dpi=300)\n        plt.close()\n\n    except ImportError:\n        logger.warning(\"Seaborn ou Matplotlib non install√©. Visualisations non g√©n√©r√©es.\")\n    except Exception as e:\n        logger.error(f\"Erreur lors de la cr√©ation des visualisations : {e}\")\n\ndef obtenir_predictions(modele, tokeniseur, phrase):\n    \"\"\"\n    Obtient les pr√©dictions de sens pour un mot ambigu dans une phrase.\n\n    Le syst√®me analyse les diff√©rents sens possibles et leurs probabilit√©s.\n    \"\"\"\n    resultat = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", phrase)\n    if resultat is None:\n        print(\"\\nFormat d'entr√©e incorrect. Veuillez r√©essayer.\")\n        return\n\n    mot_ambigu = resultat.group(1).strip()\n    cles_sens = []\n    definitions = []\n    for cle_sens, definition in obtenir_glosses(mot_ambigu, None).items():\n        cles_sens.append(cle_sens)\n        definitions.append(definition)\n\n    LONGUEUR_SEQUENCE_MAX = 128\n    enregistrement = GlossSelectionRecord(\"test\", phrase, cles_sens, definitions, [-1])\n    caracteristiques = creer_caracteristiques_depuis_enregistrements([enregistrement], LONGUEUR_SEQUENCE_MAX, tokeniseur)[0]\n\n    appareil = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    modele.to(appareil)\n\n    with torch.no_grad():\n        logits = torch.zeros(len(definitions), dtype=torch.double).to(appareil)\n        for i, entree_bert in tqdm(list(enumerate(caracteristiques)), desc=\"Progression\"):\n            logits[i] = modele.couche_classement(\n                modele.bert(\n                    input_ids=torch.tensor(entree_bert.ids_entree, dtype=torch.long).unsqueeze(0).to(appareil),\n                    attention_mask=torch.tensor(entree_bert.masque_entree, dtype=torch.long).unsqueeze(0).to(appareil),\n                    token_type_ids=torch.tensor(entree_bert.ids_segment, dtype=torch.long).unsqueeze(0).to(appareil)\n                )[1]\n            )\n        scores = softmax(logits, dim=0)\n\n    return sorted(zip(cles_sens, definitions, scores), key=lambda x: x[-1], reverse=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-21T16:27:07.321732Z","iopub.execute_input":"2024-12-21T16:27:07.322152Z","iopub.status.idle":"2024-12-21T16:27:07.341607Z","shell.execute_reply.started":"2024-12-21T16:27:07.322117Z","shell.execute_reply":"2024-12-21T16:27:07.340618Z"},"id":"anXM_SmPrFEr","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def fonction_principale():\n    \"\"\"\n    Fonction principale pour charger le mod√®le et lancer l'interaction utilisateur.\n\n    Le syst√®me permet de tester les pr√©dictions de d√©sambigu√Øsation lexicale.\n    \"\"\"\n    print(\"Chargement du mod√®le...\")\n    modele = BertWSD.from_pretrained(\"/kaggle/input/model-last\")\n    tokeniseur = BertTokenizer.from_pretrained(\"/kaggle/input/model-last\")\n    appareil = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    modele.to(appareil)\n    modele.eval()\n\n    while True:\n        phrase = input(\"\\nEntrez une phrase avec un mot ambigu entre balises [TGT]\\n> \")\n        predictions = obtenir_predictions(modele, tokeniseur, phrase)\n        if predictions:\n            print(\"\\nPr√©dictions:\")\n            print(tabulate(\n                [[f\"{i+1}.\", cle, gloss, f\"{score:.5f}\"] for i, (cle, gloss, score) in enumerate(predictions)],\n                headers=[\"N¬∞\", \"Cl√© de sens\", \"D√©finition\", \"Score\"])\n            )","metadata":{"execution":{"iopub.status.busy":"2024-12-21T11:47:52.787439Z","iopub.execute_input":"2024-12-21T11:47:52.787726Z","iopub.status.idle":"2024-12-21T11:47:52.793064Z","shell.execute_reply.started":"2024-12-21T11:47:52.787701Z","shell.execute_reply":"2024-12-21T11:47:52.792085Z"},"id":"WcySBUMfrJnB","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"if __name__ == '__main__':\n    # Options d'ex√©cution\n    #choix = input(\"Que voulez-vous faire ?\\n1. Tester des pr√©dictions interactivement\\n2. Entra√Æner le mod√®le\\n3. √âvaluer le mod√®le\\nVotre choix : \")\n\n    if choix == '1':\n        fonction_principale()\n    elif choix == '2':\n        resultats = entrainer_wsd(\n        chemin_entrainement= '/kaggle/input/datasett/corpus_dir-max_num_gloss5-augmented.csv',\n        chemin_evaluation= '/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv',\n        debut_plage_entrainement=50001,\n        fin_plage_entrainement= 263631,\n        taille_max_entrainement=150000,\n        debut_plage_evaluation=2001,\n        fin_plage_evaluation=38050,\n        taille_max_evaluation=22000\n        )\n    \n        print(f\"Meilleur score F1 obtenu : {resultats['f1']:.4f}\")\n        \n    elif choix == '3':\n        modele = BertWSD.from_pretrained('/kaggle/input/modell') #/kaggle/working/resultats\n        tokeniseur = BertTokenizer.from_pretrained('/kaggle/input/modell')\n        resultats = evaluer_wsd(\n            modele=modele,\n            tokeniseur=tokeniseur,\n            chemin_evaluation='/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv',\n            debut_plage_evaluation=None,\n            fin_plage_evaluation=None,\n            taille_max_evaluation=None\n    )\n\n        # Affichage des m√©triques si n√©cessaire\n        print(\"Pr√©cision:\", resultats['precision'])\n        print(\"Rappel:\", resultats['rappel'])\n        print(\"Score F1:\", resultats['f1_score'])\n        print(\"Matrice de Confusion:\\n\", resultats['matrice_confusion'])\n    else:\n        print(\"Choix invalide.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T11:01:43.474543Z","iopub.execute_input":"2024-12-20T11:01:43.474792Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Que voulez-vous faire ?\n1. Tester des pr√©dictions interactivement\n2. Entra√Æner le mod√®le\n3. √âvaluer le mod√®le\nVotre choix :  2\n"},{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/input/modell were not used when initializing BertWSD: ['ranking_linear.bias', 'ranking_linear.weight']\n- This IS expected if you are initializing BertWSD from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertWSD from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertWSD were not initialized from the model checkpoint at /kaggle/input/modell and are newly initialized: ['couche_classement.bias', 'couche_classement.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nConversion des donn√©es: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150000/150000 [02:51<00:00, 877.08it/s] \n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n√âpoque 1/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18750/18750 [4:52:12<00:00,  1.07lot/s, Perte=1.0915, Pr√©cision=0.8022, Taux Apprentissage=0.000033]  \n√âpoque 2/3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18750/18750 [4:54:42<00:00,  1.06lot/s, Perte=0.3767, Pr√©cision=0.8303, Taux Apprentissage=0.000017]  \n√âpoque 3/3:  19%|‚ñà‚ñä        | 3513/18750 [41:17<3:25:08,  1.24lot/s, Perte=0.2039, Pr√©cision=0.8496, Taux Apprentissage=0.000014]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    # Options d'ex√©cution\n    choix = input(\"Que voulez-vous faire ?\\n1. Tester des pr√©dictions interactivement\\n2. Entra√Æner le mod√®le\\n3. √âvaluer le mod√®le\\nVotre choix : \")\n\n    if choix == '1':\n        fonction_principale()\n    elif choix == '2':\n        resultats = entrainer_wsd(\n        chemin_entrainement= '/kaggle/input/datasett/corpus_dir-max_num_gloss5-augmented.csv',\n        chemin_evaluation= '/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv',\n        debut_plage_entrainement=50001,\n        fin_plage_entrainement= 263631,\n        taille_max_entrainement=150000,\n        debut_plage_evaluation=2001,\n        fin_plage_evaluation=38050,\n        taille_max_evaluation=22000\n        )\n    \n        print(f\"Meilleur score F1 obtenu : {resultats['f1']:.4f}\")\n        \n    elif choix == '3':\n        \n        # V√©rification des chemins des mod√®les et des donn√©es\n        chemin_modele = '/kaggle/input/modell'\n        chemin_donnees = '/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv'\n        \n        if not os.path.exists(chemin_modele):\n            print(f\"Erreur : Le chemin du mod√®le '{chemin_modele}' est introuvable.\")\n            exit(1)\n        if not os.path.exists(chemin_donnees):\n            print(f\"Erreur : Le fichier d'√©valuation '{chemin_donnees}' est introuvable.\")\n            exit(1)\n        \n        # Chargement du mod√®le et du tokenizer\n        try:\n            modele = BertWSD.from_pretrained(chemin_modele)\n            tokeniseur = BertTokenizer.from_pretrained(chemin_modele)\n        except Exception as e:\n            print(f\"Erreur lors du chargement du mod√®le ou du tokenizer : {e}\")\n            exit(1)\n        \n        # √âvaluation du mod√®le\n        try:\n            resultats = evaluer_wsd(\n                modele=modele,\n            tokeniseur=tokeniseur,\n            chemin_evaluation=chemin_donnees,\n            debut_plage_evaluation=2001,\n            fin_plage_evaluation=3001,\n            taille_max_evaluation=1000\n            \n            )\n        \n            # Affichage des r√©sultats\n            print(\"\\nüìä R√©sultats d'√©valuation :\")\n            print(\"Pr√©cision Globale (Accuracy):\", resultats['accuracy'])\n            print(f\"Pr√©cision : {resultats['precision']:.4f}\")\n            print(f\"Rappel : {resultats['rappel']:.4f}\")\n            print(f\"Score F1 : {resultats['f1_score']:.4f}\")\n            print(\"Score ROC-AUC:\", resultats['roc_auc'])\n            print(\"\\nMatrice de Confusion :\")\n            print(np.array2string(resultats['matrice_confusion'], separator=', '))\n\n        except Exception as e:\n            print(f\"Erreur lors de l'√©valuation du mod√®le : {e}\")\n            exit(1)\n    else:\n        print(\"Choix invalide.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T00:28:22.210429Z","iopub.execute_input":"2024-12-21T00:28:22.210921Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Que voulez-vous faire ?\n1. Tester des pr√©dictions interactivement\n2. Entra√Æner le mod√®le\n3. √âvaluer le mod√®le\nVotre choix :  2\n"},{"name":"stderr","text":"Conversion des donn√©es: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150000/150000 [02:56<00:00, 849.49it/s] \n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n√âpoque 1/2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18750/18750 [4:52:44<00:00,  1.07lot/s, Perte=0.0060, Pr√©cision=0.8509, Taux Apprentissage=0.000005]  \n√âpoque 2/2:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 12716/18750 [3:00:36<1:47:42,  1.07s/lot, Perte=0.0328, Pr√©cision=0.8675, Taux Apprentissage=0.000002]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    # Options d'ex√©cution\n    choix = input(\"Que voulez-vous faire ?\\n1. Tester des pr√©dictions interactivement\\n2. Entra√Æner le mod√®le\\n3. √âvaluer le mod√®le\\nVotre choix : \")\n\n    if choix == '1':\n        fonction_principale()\n    elif choix == '2':\n        resultats = entrainer_wsd(\n        chemin_entrainement= '/kaggle/input/datasett/corpus_dir-max_num_gloss5-augmented.csv',\n        chemin_evaluation= '/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv',\n        debut_plage_entrainement=50001,\n        fin_plage_entrainement= 263631,\n        taille_max_entrainement=150000,\n        debut_plage_evaluation=2001,\n        fin_plage_evaluation=38050,\n        taille_max_evaluation=22000\n        )\n    \n        print(f\"Meilleur score F1 obtenu : {resultats['f1']:.4f}\")\n        \n    elif choix == '3':\n        \n        # V√©rification des chemins des mod√®les et des donn√©es\n        chemin_modele = '/kaggle/input/modell'\n        chemin_donnees = '/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv'\n        \n        if not os.path.exists(chemin_modele):\n            print(f\"Erreur : Le chemin du mod√®le '{chemin_modele}' est introuvable.\")\n            exit(1)\n        if not os.path.exists(chemin_donnees):\n            print(f\"Erreur : Le fichier d'√©valuation '{chemin_donnees}' est introuvable.\")\n            exit(1)\n        \n        # Chargement du mod√®le et du tokenizer\n        try:\n            modele = BertWSD.from_pretrained(chemin_modele)\n            tokeniseur = BertTokenizer.from_pretrained(chemin_modele)\n        except Exception as e:\n            print(f\"Erreur lors du chargement du mod√®le ou du tokenizer : {e}\")\n            exit(1)\n        \n        # √âvaluation du mod√®le\n        try:\n            resultats = evaluer_wsd(\n                modele=modele,\n            tokeniseur=tokeniseur,\n            chemin_evaluation=chemin_donnees,\n            debut_plage_evaluation=2001,\n            fin_plage_evaluation=3001,\n            taille_max_evaluation=1000\n            \n            )\n        \n            # Affichage des r√©sultats\n            print(\"\\nüìä R√©sultats d'√©valuation :\")\n            print(\"Pr√©cision Globale (Accuracy):\", resultats['accuracy'])\n            print(f\"Pr√©cision : {resultats['precision']:.4f}\")\n            print(f\"Rappel : {resultats['rappel']:.4f}\")\n            print(f\"Score F1 : {resultats['f1_score']:.4f}\")\n            print(\"Score ROC-AUC:\", resultats['roc_auc'])\n            print(\"\\nMatrice de Confusion :\")\n            print(np.array2string(resultats['matrice_confusion'], separator=', '))\n\n        except Exception as e:\n            print(f\"Erreur lors de l'√©valuation du mod√®le : {e}\")\n            exit(1)\n    else:\n        print(\"Choix invalide.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T11:49:00.879983Z","iopub.execute_input":"2024-12-21T11:49:00.880306Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Que voulez-vous faire ?\n1. Tester des pr√©dictions interactivement\n2. Entra√Æner le mod√®le\n3. √âvaluer le mod√®le\nVotre choix :  2\n"},{"name":"stderr","text":"Conversion des donn√©es: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150000/150000 [02:56<00:00, 850.74it/s] \n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n√âpoque 1/1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 14348/18750 [3:22:25<1:18:12,  1.07s/lot, Perte=0.0000, Pr√©cision=0.9124, Taux Apprentissage=0.000002]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n\n  # Options d'ex√©cution\n  choix = input(\"Que voulez-vous faire ?\\n1. Tester des pr√©dictions interactivement\\n2. Entra√Æner le mod√®le\\n3. √âvaluer le mod√®le\\nVotre choix : \")\n\n  if choix == '1':\n      fonction_principale()\n  elif choix == '2':\n\n    resultats = entrainer_wsd(\n    chemin_entrainement= '/kaggle/input/dataset/corpus_dir-max_num_gloss5-augmented.csv',\n    chemin_evaluation= '/kaggle/input/dataset/semeval2007-max_num_gloss5-augmented.csv',\n    debut_plage_entrainement=50001,\n    fin_plage_entrainement= 263631,\n    taille_max_entrainement=150000,\n    debut_plage_evaluation=2001,\n    fin_plage_evaluation=38050,\n    taille_max_evaluation=22000\n    )\n\n    print(f\"Meilleur score F1 obtenu : {resultats['f1']:.4f}\")\n\n  elif choix == '3':\n      modele = BertWSD.from_pretrained('/kaggle/input/model-last')\n      tokeniseur = BertTokenizer.from_pretrained('/kaggle/input/model-last')\n      resultats = evaluer_wsd(\n          modele=modele,\n          tokeniseur=tokeniseur,\n          chemin_evaluation='/kaggle/input/datasett/semeval2007-max_num_gloss5-augmented.csv',\n          debut_plage_evaluation=2001,\n          fin_plage_evaluation=12001, #38050,\n          taille_max_evaluation=10000\n      )\n\n      print(\"\\nüìä R√©sultats de l'√©valuation :\")\n\n      for metrique, valeur in resultats.items():\n          if metrique == 'matrice_confusion':\n              print(f\"{metrique.capitalize()} :\\n{valeur}\")\n          else:\n              print(f\"{metrique.capitalize()} : {valeur:.4f}\")\n  else:\n    print(\"Choix invalide.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T16:30:56.146992Z","iopub.execute_input":"2024-12-21T16:30:56.147378Z","iopub.status.idle":"2024-12-21T16:35:33.212689Z","shell.execute_reply.started":"2024-12-21T16:30:56.147348Z","shell.execute_reply":"2024-12-21T16:35:33.211790Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Que voulez-vous faire ?\n1. Tester des pr√©dictions interactivement\n2. Entra√Æner le mod√®le\n3. √âvaluer le mod√®le\nVotre choix :  3\n"},{"name":"stderr","text":"Conversion des donn√©es: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:08<00:00, 1236.63it/s]\n√âvaluation en cours: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 625/625 [04:21<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nüìä R√©sultats de l'√©valuation :\nPerte : 2.8822\nAccuracy : 0.7390\nBalanced_accuracy : 0.6536\nPrecision : 0.5454\nRappel : 0.4572\nF1_score : 0.4974\nMcc : 0.3253\nSpecificity : 0.8500\nRoc_auc : 0.6536\nMatrice_confusion :\n[[21588  3811]\n [ 5428  4572]]\n","output_type":"stream"}],"execution_count":9}]}