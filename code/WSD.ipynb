{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71cd360",
   "metadata": {},
   "source": [
    "# Étape 1 : Analyse des phrases dans le fichier XML\n",
    "Les fichiers .data.xml contiennent des phrases ou des contextes annotés, tandis que les fichiers .gold.key.txt associent les mots cibles à leurs sens (par exemple, des BabelNet IDs).\n",
    "\n",
    "### Extrait des fichiers XML : \n",
    "Utilisation de la bibliothèque xml.etree.ElementTree pour extraire les phrases et mots annotés : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcacba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_data(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    sentences = []\n",
    "\n",
    "    for text in root.findall('.//text'):  # Parcourt les textes\n",
    "        for sentence in text.findall('.//sentence'):  # Parcourt les phrases\n",
    "            words = []\n",
    "            # Ne garde que les mots annotés comme <instance>\n",
    "            for instance in sentence.findall('.//instance'):  # Trouve les mots annotés \"instance\"\n",
    "                words.append(instance.text)\n",
    "            sentences.append(\" \".join(words))  # Concatène les mots annotés\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f232eaf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sociétés participation enchères', 'professeur microbiologie idée arsenic phosphore', 'vendredi altercations négociations semaine', 'bataille sauvetage économies sauvetage planète Chine Etats-Unis obligations nations fait douzaines pays', 'humeur']\n"
     ]
    }
   ],
   "source": [
    "# Test avec le fichier XML\n",
    "file_path = r\"C:\\Users\\pc\\Downloads\\BIBDA\\S3\\Analyse de Sentiments et Text Mining\\french-data\\evaluation_datasets_fr\\dev-fr\\dev-fr.data.xml\"\n",
    "sentences = parse_data(file_path)\n",
    "\n",
    "print(sentences[:5])  # Affiche les 5 premières phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b293fb4",
   "metadata": {},
   "source": [
    "# Étape 2 : Association des mots annotés avec leurs identifiants de sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20349f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gold_keys(file_path):\n",
    "    gold_keys = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                instance_id = parts[0]\n",
    "                # Si plusieurs sens sont associés à l'instance, les ajouter dans une liste\n",
    "                sense_ids = parts[1:]\n",
    "                gold_keys[instance_id] = sense_ids\n",
    "            else:\n",
    "                print(f\"Ligne ignorée (format incorrect): {line}\")  # Affiche une ligne mal formatée\n",
    "    return gold_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2e85ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d000.s000.t000', ['bn:00021286n']), ('d000.s000.t001', ['bn:00070915n']), ('d000.s000.t002', ['bn:00007085n']), ('d000.s001.t000', ['bn:00064601n']), ('d000.s001.t001', ['bn:00054734n'])]\n"
     ]
    }
   ],
   "source": [
    "# Test avec le fichier gold key\n",
    "gold_key_path = r\"C:\\Users\\pc\\Downloads\\BIBDA\\S3\\Analyse de Sentiments et Text Mining\\french-data\\evaluation_datasets_fr\\dev-fr\\dev-fr.gold.key.txt\"\n",
    "gold_keys = parse_gold_keys(gold_key_path)\n",
    "\n",
    "print(list(gold_keys.items())[:5])  # Affiche les 5 premiers mappings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75dbf82",
   "metadata": {},
   "source": [
    "# Étape 3 : Associer les phrases avec leurs annotations \n",
    "Nous combinons les phrases et les identifiants de sens en utilisant les informations du fichier gold key :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "135dd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_annotations(file_path, gold_keys):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    annotations = []\n",
    "\n",
    "    for text in root.findall('.//text'):\n",
    "        for sentence in text.findall('.//sentence'):\n",
    "            sentence_id = sentence.attrib['id']  # ID de la phrase\n",
    "            annotated_words = []\n",
    "            for instance in sentence.findall('.//instance'):  # Parcourt les instances annotées\n",
    "                instance_id = instance.attrib['id']  # ID de l'instance\n",
    "                word = instance.text\n",
    "                sense_id = gold_keys.get(instance_id, \"unknown\")  # Récupère l'identifiant de sens\n",
    "                annotated_words.append((word, sense_id))\n",
    "            annotations.append((sentence_id, annotated_words))\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "211e07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: d000.s000\n",
      "  Word: sociétés, Sense ID: ['bn:00021286n']\n",
      "  Word: participation, Sense ID: ['bn:00070915n']\n",
      "  Word: enchères, Sense ID: ['bn:00007085n']\n",
      "Sentence ID: d000.s001\n",
      "  Word: professeur, Sense ID: ['bn:00064601n']\n",
      "  Word: microbiologie, Sense ID: ['bn:00054734n']\n",
      "  Word: idée, Sense ID: ['bn:00045800n']\n",
      "  Word: arsenic, Sense ID: ['bn:00005917n']\n",
      "  Word: phosphore, Sense ID: ['bn:00006845n']\n",
      "Sentence ID: d000.s002\n",
      "  Word: vendredi, Sense ID: ['bn:00036512n']\n",
      "  Word: altercations, Sense ID: ['bn:00001789n']\n",
      "  Word: négociations, Sense ID: ['bn:00026838n']\n",
      "  Word: semaine, Sense ID: ['bn:00043484n']\n",
      "Sentence ID: d000.s003\n",
      "  Word: bataille, Sense ID: ['bn:00009078n']\n",
      "  Word: sauvetage, Sense ID: ['bn:00026061n']\n",
      "  Word: économies, Sense ID: ['bn:00029678n']\n",
      "  Word: sauvetage, Sense ID: ['bn:00026061n']\n",
      "  Word: planète, Sense ID: ['bn:00052888n']\n",
      "  Word: Chine, Sense ID: ['bn:00016756n']\n",
      "  Word: Etats-Unis, Sense ID: ['bn:00003341n']\n",
      "  Word: obligations, Sense ID: ['bn:00029239n']\n",
      "  Word: nations, Sense ID: ['bn:00023236n']\n",
      "  Word: fait, Sense ID: ['bn:00032654n']\n",
      "  Word: douzaines, Sense ID: ['bn:00000020n']\n",
      "  Word: pays, Sense ID: ['bn:00023236n']\n",
      "Sentence ID: d000.s004\n",
      "  Word: humeur, Sense ID: ['bn:00045201n']\n"
     ]
    }
   ],
   "source": [
    "# Associer annotations\n",
    "annotations = associate_annotations(file_path, gold_keys)\n",
    "\n",
    "# Afficher les 5 premières annotations\n",
    "for sentence_id, annotated_words in annotations[:5]:\n",
    "    print(f\"Sentence ID: {sentence_id}\")\n",
    "    for word, sense_id in annotated_words:\n",
    "        print(f\"  Word: {word}, Sense ID: {sense_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35779731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0df43fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase : sociétés participation enchères\n",
      "Annotations : ('d000.s000', [('sociétés', ['bn:00021286n']), ('participation', ['bn:00070915n']), ('enchères', ['bn:00007085n'])])\n",
      "Phrase : professeur microbiologie idée arsenic phosphore\n",
      "Annotations : ('d000.s001', [('professeur', ['bn:00064601n']), ('microbiologie', ['bn:00054734n']), ('idée', ['bn:00045800n']), ('arsenic', ['bn:00005917n']), ('phosphore', ['bn:00006845n'])])\n",
      "Phrase : vendredi altercations négociations semaine\n",
      "Annotations : ('d000.s002', [('vendredi', ['bn:00036512n']), ('altercations', ['bn:00001789n']), ('négociations', ['bn:00026838n']), ('semaine', ['bn:00043484n'])])\n",
      "Phrase : bataille sauvetage économies sauvetage planète Chine Etats-Unis obligations nations fait douzaines pays\n",
      "Annotations : ('d000.s003', [('bataille', ['bn:00009078n']), ('sauvetage', ['bn:00026061n']), ('économies', ['bn:00029678n']), ('sauvetage', ['bn:00026061n']), ('planète', ['bn:00052888n']), ('Chine', ['bn:00016756n']), ('Etats-Unis', ['bn:00003341n']), ('obligations', ['bn:00029239n']), ('nations', ['bn:00023236n']), ('fait', ['bn:00032654n']), ('douzaines', ['bn:00000020n']), ('pays', ['bn:00023236n'])])\n",
      "Phrase : humeur\n",
      "Annotations : ('d000.s004', [('humeur', ['bn:00045201n'])])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Phrase : {sentences[i]}\")\n",
    "    print(f\"Annotations : {annotations[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189910d",
   "metadata": {},
   "source": [
    "# Resultats\n",
    "\n",
    "Extraction des données XML : Les phrases ont été correctement extraites à partir du fichier XML, en se concentrant sur les instances annotées.\n",
    "Gestion des clés dorées (gold keys) : Les clés dorées (celles correspondant aux sens des mots) ont été extraites et plusieurs identifiants de sens sont gérés correctement pour une même instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d4f16",
   "metadata": {},
   "source": [
    "# Prochaine étape : Désambiguïsation des mots avec un modèle Transformers\n",
    "Maintenant que les données sont correctement extraites et annotées, la prochaine étape serait d'appliquer un modèle de désambiguïsation de sens (Word Sense Disambiguation - WSD) utilisant un modèle de type Transformers.\n",
    "\n",
    "Pour cela, on peux utiliser des modèles pré-entraînés comme BERT, RoBERTa (version améliorés de BERT), ou XLM-R (version multilingue de BERT) qui sont bien adaptés pour les tâches de désambiguïsation des mots. Ces modèles sont disponibles via la bibliothèque transformers de Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69249f65",
   "metadata": {},
   "source": [
    "# BERT ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfef71",
   "metadata": {},
   "source": [
    "# RoBERTa ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b04684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "676d0405",
   "metadata": {},
   "source": [
    "###### Conversion en JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3625d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Association entre phrases et annotations\n",
    "sentence_ids = list(annotations.keys())\n",
    "dataset = []\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if i < len(sentence_ids):  # S'assurer que chaque phrase a des annotations\n",
    "        dataset.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"annotations\": annotations[sentence_ids[i]]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08309520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder en JSON\n",
    "output_path = r\"C:\\Users\\pc\\Downloads\\BIBDA\\S3\\Analyse de Sentiments et Text Mining\\french-data\\french_wsd_dataset.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(dataset, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba01b41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sauvegardé dans C:\\Users\\pc\\Downloads\\BIBDA\\S3\\Analyse de Sentiments et Text Mining\\french-data\\french_wsd_dataset.json\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset sauvegardé dans {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec81e957",
   "metadata": {},
   "source": [
    "###### Conversion en pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ceeb538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if i < len(sentence_ids):\n",
    "        for annotation in annotations[sentence_ids[i]]:\n",
    "            rows.append({\n",
    "                \"sentence\": sentence,\n",
    "                \"word\": annotation[\"word\"],\n",
    "                \"sense\": annotation[\"sense\"]\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9708c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder en CSV\n",
    "csv_path = r\"C:\\Users\\pc\\Downloads\\BIBDA\\S3\\Analyse de Sentiments et Text Mining\\french-data\\french_wsd_dataset.csv\"\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbc49173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sauvegardé dans C:\\Users\\pc\\Downloads\\BIBDA\\S3\\Analyse de Sentiments et Text Mining\\french-data\\french_wsd_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset sauvegardé dans {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf1509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
